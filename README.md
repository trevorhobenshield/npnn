# npnn

### `mlp.py`
Simple MLP in NumPy implementing mini-batch SGD with L2 Regularization and Dropout.

`f`,`df`: affine function and it's derivative

`C`,`dC`: loss function and it's derivative

`gW`,`gb`: gradients w.r.t. the model's parameters

